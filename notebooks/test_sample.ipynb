{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vlad\\\\Desktop\\\\BeansAI'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Настройка путей (запускать один раз!)\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-like архитектура\n",
    "class CoffeeCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 64, (3, 3), padding=1)\n",
    "    self.act = nn.ReLU()\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv2 = nn.Conv2d(64, 128, (3, 3), padding=1)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(128, 256, (3, 3), padding=1)\n",
    "    self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv4 = nn.Conv2d(256, 512, (3, 3), padding=1)\n",
    "    self.pool4 = nn.MaxPool2d(2)\n",
    "    self.adapool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "    self.flat = nn.Flatten()\n",
    "    self.drop = nn.Dropout(0.5)\n",
    "    self.lin1 = nn.Linear(512 * 6 * 6, 512)\n",
    "    self.lin2 = nn.Linear(512, 128)\n",
    "    self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool1(self.act(self.conv1(x)))\n",
    "    x = self.pool2(self.act(self.conv2(x)))\n",
    "    x = self.pool3(self.act(self.conv3(x)))\n",
    "    x = self.pool4(self.act(self.conv4(x)))\n",
    "    x = self.adapool(x)\n",
    "    x = self.flat(x)\n",
    "    x = self.drop(self.act(self.lin1(x)))\n",
    "    x = self.drop(self.act(self.lin2(x)))\n",
    "    out = self.lin3(x)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_sample():\n",
    "    #Загрузка весов и классов модели, используем cpu\n",
    "    params = torch.load(\"app/models/coffee_model_best.pth\", map_location=\"cpu\")\n",
    "    classes = params['classes']\n",
    "\n",
    "    #Инициализация модели \n",
    "    new_model = CoffeeCNN()\n",
    "    new_model.load_state_dict(params['model_state_dict'])\n",
    "\n",
    "    #Трансформации\n",
    "    T = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)), torchvision.transforms.ToTensor()])\n",
    "\n",
    "    #Открываем изображение по относительному пути и делаем предобработку\n",
    "    image_pth = \"app/data/dark.png\"\n",
    "    image = Image.open(image_pth)\n",
    "    image = T(image)\n",
    "\n",
    "    #Переводим модель в тестовый режим\n",
    "    new_model.eval()\n",
    "\n",
    "    #Получаем уверенность модели и предсказанный класс в читаемом виде\n",
    "    prediction = new_model(image.unsqueeze(0))\n",
    "    prediction = torch.softmax(prediction, dim=1)\n",
    "    conf, cls = torch.max(prediction, 1)\n",
    "    return f\"Уверенность - {round(conf.item(), 4)}, класс: {classes[cls.item()]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уверенность - 0.9893, класс: Dark\n"
     ]
    }
   ],
   "source": [
    "print(prediction_sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
